{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras示例\n",
    "### Keras是一个高度模块化的神经网络库，运行在Theano或TensorFlow之上。\n",
    "### Keras是同时支持卷积神经网络和循环神经网络的库之一，并且可以毫不费力地运行在GPU和CPU上。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras原理\n",
    "#### Keras中提供的每个模型都是可定制的实体，可以由不同的层、损失函数、激活函数和正则化模式组成。\n",
    "#### Keras提供各种预先构建的层来插入神经网络，其中一些包括卷积、汇集、本地连接、循环、噪声和标准化层。网络的个体层被认为是下一的输入对象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras的基本数据类型是模型类型，它由网络的不同层组成。序列模型是Keras中的主要模型类型，其中的层会逐层增加，直到最终输出层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.00e+00 5.00e+01 1.25e+04 9.80e+01]\n",
      " [0.00e+00 1.30e+01 3.25e+03 2.80e+01]\n",
      " [1.00e+00 1.60e+01 4.00e+03 3.50e+01]\n",
      " ...\n",
      " [2.30e+01 3.00e+00 7.50e+02 6.20e+01]\n",
      " [3.90e+01 1.00e+00 2.50e+02 3.90e+01]\n",
      " [7.20e+01 1.00e+00 2.50e+02 7.20e+01]]\n"
     ]
    }
   ],
   "source": [
    "# Importing the required libraries and layers and model from Keras\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "\n",
    "# Dataset Link: # https://archive.ics.uci.edu/ml/datasets/Blood+Transfusion+Service+Center\n",
    "# Save the dataset as a .csv file:\n",
    "tran_ = np.genfromtxt('transfusion.csv', delimiter=',')\n",
    "X = tran_[1:, 0:4] # The dataset offers 4 input variables\n",
    "Y = tran_[1:, 4]   # Target variable with '1' and '0'\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748/748 [==============================] - 0s 267us/step\n",
      "Accuracy : 78.88% \n"
     ]
    }
   ],
   "source": [
    "# 利用Keras中由密集层定义的完全连接层来构建附加层。网络结构的选择是基于问题的复杂性来完成的\n",
    "# Creating our first MLP model with Keras\n",
    "mlp_keras = Sequential()\n",
    "# 第一个隐含层由8个神经元组成，该层已使用均匀分布的随机数进行初始化，input_dim指输入变量的个数\n",
    "# init='uniform' 改成 kernel_initializer='uniform'，否则报错\n",
    "mlp_keras.add(Dense(8, input_dim=4, kernel_initializer='uniform', activation='relu')) \n",
    "# 第二层有6个神经元\n",
    "mlp_keras.add(Dense(6, kernel_initializer='uniform', activation='relu'))\n",
    "# 最后输出层，使用sigmoid，有助于二元分类(0,1)\n",
    "mlp_keras.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "\n",
    "# 使用对数损失的二进制分类，并选择Adam作为默认选择的优化器，并将准确率作为要跟踪的指标\n",
    "# 通过反向传播算法，以及给定的优化算法和损失函数来训练网络\n",
    "mlp_keras.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 模型的批量大小是一个可行的值，并使用少量的迭代对给定数据集进行训练\n",
    "mlp_keras.fit(X, Y, epochs=200, batch_size=8, verbose=0) # The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
    "\n",
    "# 最终评估已构建的模型，并检查初始训练数据集的性能指标、损失和准确性\n",
    "accuracy = mlp_keras.evaluate(X, Y)\n",
    "print(\"Accuracy : %.2f%% \" % (accuracy[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748/748 [==============================] - 0s 31us/step\n",
      "Accuracy: 76.20%\n"
     ]
    }
   ],
   "source": [
    "# 如果想使用不同的参数组合和其他调整来进一步优化，可以在模型创建和检验室使用不同的参数和步骤，尽管这样并不总是能产生更好的性能\n",
    "# Using a different set of optimizer: 随机梯度下降\n",
    "from keras.optimizers import SGD\n",
    "opt = SGD(lr=0.01)\n",
    "\n",
    "mlp_optim = Sequential()\n",
    "# init='uniform' 改成 kernel_initializer='uniform'，否则报错\n",
    "mlp_optim.add(Dense(8, input_dim=4, kernel_initializer='uniform', activation='relu'))\n",
    "mlp_optim.add(Dense(6, kernel_initializer='uniform', activation='relu'))\n",
    "mlp_optim.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "# Compiling the model with SGD\n",
    "mlp_optim.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# Fitting the model and checking accuracy\n",
    "mlp_optim.fit(X, Y, validation_split=0.3, epochs=150, batch_size=10, verbose=0)\n",
    "results_optim = mlp_optim.evaluate(X, Y)\n",
    "print(\"Accuracy: %.2f%%\" % (results_optim[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
